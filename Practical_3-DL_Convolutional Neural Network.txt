PRACTICAL 3:

3 Convolutional Neural Networks (Classification)  
a. 
Implementing deep neural network for performing binary classification task 
b. 
Using a deep feed-forward network with two hidden layers for performing multiclass classification and predicting the class. 
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Practical 3: Convolutional Neural Networks (Classification) 
A) Implementing deep neural network for performing binary classification task. 

Code: 
import tensorflow as tf 
from tensorflow.keras import layers, models 
from tensorflow.keras.preprocessing.image import ImageDataGenerator 
from sklearn.model_selection import train_test_split 
import numpy as np 
import os 
 
# Generate synthetic binary classification dataset (e.g., using 
random noise as an example) 
def create_synthetic_data(num_samples=1000, image_size=(64, 64)): 
    np.random.seed(42) 
    X = np.random.rand(num_samples, *image_size, 3) 
    y = np.random.randint(0, 2, num_samples)  # Binary labels (0 or 
1) 
    return X, y 
 
# Step 1: Create dataset 
image_size = (64, 64)  # Image dimensions 
num_samples = 1000 
X, y = create_synthetic_data(num_samples, image_size) 
 
# Step 2: Split data into training and testing sets 
X_train, X_test, y_train, y_test = train_test_split(X, y, 
test_size=0.2, random_state=42) 
 
# Step 3: Build the CNN model 
model = models.Sequential([ 
    layers.Conv2D(32, (3, 3), activation='relu', 
input_shape=(*image_size, 3)), 
    layers.MaxPooling2D((2, 2)), 
 
    layers.Conv2D(64, (3, 3), activation='relu'), 
    layers.MaxPooling2D((2, 2)), 
 
    layers.Conv2D(128, (3, 3), activation='relu'), 
    layers.MaxPooling2D((2, 2)), 
 
    layers.Flatten(), 
    layers.Dense(128, activation='relu'), 
    layers.Dense(1, activation='sigmoid')  # Output layer for binary 
classification 
]) 
 
# Step 4: Compile the model 
model.compile(optimizer='adam', 
              loss='binary_crossentropy', 
              metrics=['accuracy']) 
 
# Step 5: Train the model 
history = model.fit( 
    X_train, y_train, 
    epochs=10, 
    batch_size=32, 
    validation_split=0.2 
) 
 
# Step 6: Evaluate the model 
loss, accuracy = model.evaluate(X_test, y_test) 
print(f"Test Loss: {loss:.4f}") 
print(f"Test Accuracy: {accuracy:.4f}") 
 
# Step 7: Save the model 
model.save("binary_classification_cnn.h5") 
print("Model saved successfully.") 


Output: 
Epoch 1/10 
/usr/local/lib/python3.11/dist
packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: 
Do not pass an `input_shape`/`input_dim` argument to a layer. When using 
Sequential models, prefer using an `Input(shape)` object as the first 
layer in the model instead. 
  super().__init__(activity_regularizer=activity_regularizer, **kwargs) 
20/20 ━━━━━━━━━━━━━━━━━━━━ 5s 56ms/step - accuracy: 0.5418 - loss: 0.8025 - val_accuracy: 0.4437 - val_loss: 0.6936 
Epoch 2/10 
20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.4848 - loss: 0.6934 - val_accuracy: 0.4437 - val_loss: 0.7017 
Epoch 3/10 
20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.5455 - loss: 0.6910 - val_accuracy: 0.4437 - val_loss: 0.6969 
Epoch 4/10 
20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.5154 - loss: 0.6927 - val_accuracy: 0.4437 - val_loss: 0.7037 
Epoch 5/10 
20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.5516 - loss: 0.6881 - val_accuracy: 0.4437 - val_loss: 0.7010 
Epoch 6/10 
20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.5307 - loss: 0.6906 - val_accuracy: 0.4437 - val_loss: 0.7003 
Epoch 7/10 
20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.5344 - loss: 0.6901 - val_accuracy: 0.4437 - val_loss: 0.7012 
Epoch 8/10 
20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.5294 - loss: 0.6891 - val_accuracy: 0.4437 - val_loss: 0.6998 
Epoch 9/10 
20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.5364 - loss: 0.6863 - val_accuracy: 0.4437 - val_loss: 0.7106 
Epoch 10/10 
20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - accuracy: 0.5351 - loss: 0.6820 - val_accuracy: 0.4250 - val_loss: 0.6963 
7/7 ━━━━━━━━━━━━━━━━━━━━ 1s 87ms/step - accuracy: 0.5297 - 
loss: 0.6927 
WARNING:absl:You are saving your model as an HDF5 file via 
`model.save()` or `keras.saving.save_model(model)`. This file format is 
considered legacy. We recommend using instead the native Keras format, 
e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 
'my_model.keras')`.  
Test Loss: 0.6935 
Test Accuracy: 0.4950 
Model saved successfully.



B) Using a deep feed-forward network with two hidden layers for performing multiclass classification and predicting the class. 

Code: 
import numpy as np 
import matplotlib.pyplot as plt 
from tensorflow.keras.datasets import mnist 
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Dense, Flatten, Conv2D, 
MaxPooling2D, Dropout 
from tensorflow.keras.utils import to_categorical 
 
(x_train, y_train), (x_test, y_test) = mnist.load_data() 
 
# Normalize the pixel values 
x_train = x_train / 255.0 
x_test = x_test / 255.0 
 
# One-hot encoding of labels 
y_train_cat = to_categorical(y_train, 10) 
y_test_cat = to_categorical(y_test, 10) 
 
dnn_model = Sequential() 
dnn_model.add(Flatten(input_shape=(28, 28))) 
dnn_model.add(Dense(128, activation='relu')) 
dnn_model.add(Dense(64, activation='relu')) 
dnn_model.add(Dense(10, activation='softmax')) 
 
dnn_model.compile(optimizer='adam', loss='categorical_crossentropy', 
metrics=['accuracy']) 
 
dnn_model.fit(x_train, y_train_cat, epochs=10, batch_size=128, 
validation_split=0.2) 
 
dnn_loss, dnn_acc = dnn_model.evaluate(x_test, y_test_cat) 
print("DNN Test Accuracy:", dnn_acc) 
 
x_train_cnn = x_train.reshape(-1, 28, 28, 1) 
x_test_cnn = x_test.reshape(-1, 28, 28, 1) 
 
cnn_model = Sequential() 
cnn_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', 
input_shape=(28, 28, 1))) 
cnn_model.add(MaxPooling2D(pool_size=(2, 2))) 
cnn_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu')) 
cnn_model.add(MaxPooling2D(pool_size=(2, 2))) 
cnn_model.add(Flatten()) 
cnn_model.add(Dense(128, activation='relu')) 
cnn_model.add(Dense(10, activation='softmax')) 
cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', 
metrics=['accuracy']) 
cnn_model.fit(x_train_cnn, y_train_cat, epochs=10, batch_size=128, 
validation_split=0.2) 
cnn_loss, cnn_acc = cnn_model.evaluate(x_test_cnn, y_test_cat) 
print("CNN Test Accuracy:", cnn_acc) 
print(f"DNN Accuracy: {dnn_acc * 100:.2f}%") 
print(f"CNN Accuracy: {cnn_acc * 100:.2f}%") 


Output: 
Downloading data from https://storage.googleapis.com/tensorflow/tf
keras-datasets/mnist.npz 
11490434/11490434 ━━━━━━━━━━━━━━━━━━━━ 2s 0us/step 
/usr/local/lib/python3.11/dist
packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not 
pass an `input_shape`/`input_dim` argument to a layer. When using 
Sequential models, prefer using an `Input(shape)` object as the first 
layer in the model instead. 
super().__init__(**kwargs) 
Epoch 1/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 4s 5ms/step - accuracy: 
0.8089 - loss: 0.7009 - val_accuracy: 0.9455 - val_loss: 0.1932 
Epoch 2/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 
0.9528 - loss: 0.1652 - val_accuracy: 0.9588 - val_loss: 0.1390 
Epoch 3/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 
0.9691 - loss: 0.1070 - val_accuracy: 0.9641 - val_loss: 0.1157 
Epoch 4/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 
0.9765 - loss: 0.0787 - val_accuracy: 0.9690 - val_loss: 0.1035 
Epoch 5/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - accuracy: 
0.9820 - loss: 0.0604 - val_accuracy: 0.9703 - val_loss: 0.0974 
Epoch 6/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step - accuracy: 
0.9854 - loss: 0.0465 - val_accuracy: 0.9736 - val_loss: 0.0922 
Epoch 7/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 
0.9890 - loss: 0.0379 - val_accuracy: 0.9730 - val_loss: 0.0903 
Epoch 8/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 
0.9922 - loss: 0.0279 - val_accuracy: 0.9740 - val_loss: 0.0891 
Epoch 9/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 
0.9938 - loss: 0.0227 - val_accuracy: 0.9737 - val_loss: 0.0931 
Epoch 10/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 
0.9944 - loss: 0.0201 - val_accuracy: 0.9754 - val_loss: 0.0901 
313/313 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 
0.9739 - loss: 0.0931 
DNN Test Accuracy: 0.9779999852180481 
Epoch 1/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 6s 9ms/step - accuracy: 
0.8517 - loss: 0.5190 - val_accuracy: 0.9766 - val_loss: 0.0779 
Epoch 2/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 
0.9798 - loss: 0.0684 - val_accuracy: 0.9818 - val_loss: 0.0623 
Epoch 3/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 
0.9854 - loss: 0.0460 - val_accuracy: 0.9866 - val_loss: 0.0460 
Epoch 4/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 
0.9884 - loss: 0.0367 - val_accuracy: 0.9854 - val_loss: 0.0520 
Epoch 5/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 
0.9917 - loss: 0.0261 - val_accuracy: 0.9839 - val_loss: 0.0542 
Epoch 6/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 
0.9932 - loss: 0.0217 - val_accuracy: 0.9901 - val_loss: 0.0362 
Epoch 7/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 
0.9949 - loss: 0.0163 - val_accuracy: 0.9866 - val_loss: 0.0491 
Epoch 8/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 
0.9948 - loss: 0.0159 - val_accuracy: 0.9898 - val_loss: 0.0370 
Epoch 9/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 3s 5ms/step - accuracy: 
0.9963 - loss: 0.0111 - val_accuracy: 0.9895 - val_loss: 0.0376 
Epoch 10/10 
375/375 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - accuracy: 
0.9971 - loss: 0.0092 - val_accuracy: 0.9873 - val_loss: 0.0517 
313/313 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - accuracy: 
0.9854 - loss: 0.0529 
CNN Test Accuracy: 0.9882000088691711 
DNN Accuracy: 97.80% 
CNN Accuracy: 98.82% 
