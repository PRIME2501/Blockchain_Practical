PRACTICAL 8:

Practical 8: Write a program to develop Autoencoders using MNIST Handwritten Digits. 

Code: 
import tensorflow as tf 
import numpy as np 
import matplotlib.pyplot as plt 
 
# Load MNIST dataset 
(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data() 
 
# Normalize pixel values to [0, 1] 
x_train = x_train.astype('float32') / 255. 
x_test = x_test.astype('float32') / 255. 
 
# Reshape data for the autoencoder 
x_train = np.reshape(x_train, (len(x_train), 28, 28, 1)) 
x_test = np.reshape(x_test, (len(x_test), 28, 28, 1)) 
 
# Define the autoencoder architecture 
input_img = tf.keras.Input(shape=(28, 28, 1)) 
 
# Encoder 
x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', 
padding='same')(input_img) 
x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x) 
x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', 
padding='same')(x) 
encoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x) 
 
# Decoder 
x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', 
padding='same')(encoded) 
x = tf.keras.layers.UpSampling2D((2, 2))(x) 
x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', 
padding='same')(x) 
x = tf.keras.layers.UpSampling2D((2, 2))(x) 
decoded = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', 
padding='same')(x) 
 
# Create the autoencoder model 
autoencoder = tf.keras.Model(input_img, decoded) 
 
# Compile the model 
autoencoder.compile(optimizer='adam', loss='binary_crossentropy') 
 
# Train the autoencoder 
autoencoder.fit(x_train, x_train, 
                epochs=10, 
                batch_size=128, 
                shuffle=True, 
                validation_data=(x_test, x_test)) 
 
# Reconstruct images using the trained autoencoder 
decoded_imgs = autoencoder.predict(x_test) 
 
# Display the original and reconstructed images 
n = 10 
plt.figure(figsize=(20, 4)) 
for i in range(n): 
    # Display original 
    ax = plt.subplot(2, n, i + 1) 
    plt.imshow(x_test[i].reshape(28, 28)) 
    plt.gray() 
    ax.get_xaxis().set_visible(False) 
    ax.get_yaxis().set_visible(False) 
 
    # Display reconstruction 
    ax = plt.subplot(2, n, i + 1 + n) 
    plt.imshow(decoded_imgs[i].reshape(28, 28)) 
    plt.gray() 
    ax.get_xaxis().set_visible(False) 
    ax.get_yaxis().set_visible(False) 
plt.show() 

 
Output: 
Epoch 1/10 
469/469 ━━━━━━━━━━━━━━━━━━━━ 9s 11ms/step - loss: 0.1872 - 
val_loss: 0.0770 
Epoch 2/10 
469/469 ━━━━━━━━━━━━━━━━━━━━ 3s 6ms/step - loss: 0.0760 - 
val_loss: 0.0725 
Epoch 3/10 
469/469 ━━━━━━━━━━━━━━━━━━━━ 5s 6ms/step - loss: 0.0723 - 
val_loss: 0.0707 
Epoch 4/10 
469/469 ━━━━━━━━━━━━━━━━━━━━ 5s 6ms/step - loss: 0.0707 - 
val_loss: 0.0691 
Epoch 5/10 
469/469 ━━━━━━━━━━━━━━━━━━━━ 5s 6ms/step - loss: 0.0696 - 
val_loss: 0.0682 
Epoch 6/10 
469/469 ━━━━━━━━━━━━━━━━━━━━ 5s 6ms/step - loss: 0.0686 - 
val_loss: 0.0677 
Epoch 7/10 
469/469 ━━━━━━━━━━━━━━━━━━━━ 5s 7ms/step - loss: 0.0680 - 
val_loss: 0.0670 
Epoch 8/10 
469/469 ━━━━━━━━━━━━━━━━━━━━ 5s 6ms/step - loss: 0.0674 - 
val_loss: 0.0670 
Epoch 9/10 
469/469 ━━━━━━━━━━━━━━━━━━━━ 3s 6ms/step - loss: 0.0670 - 
val_loss: 0.0663 
Epoch 10/10 
469/469 ━━━━━━━━━━━━━━━━━━━━ 5s 6ms/step - loss: 0.0666 - 
val_loss: 0.0661 
313/313 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step 
